[["Map",1,2,9,10,110,111,150,151,223,224],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.14.1","content-config-digest","483ae5495a417c99","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://semio-community.github.io/\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":true,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"prefetch\":true,\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[\"webmention.io\"],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":false,\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[null,null,null],\"rehypePlugins\":[[null,{\"rel\":[\"nofollow\",\"noreferrer\"],\"target\":\"_blank\"}],[null,{\"theme\":{\"light\":\"rose-pine-dawn\",\"dark\":\"rose-pine\"},\"transformers\":[{\"name\":\"@shikijs/transformers:notation-diff\"},{\"name\":\"@shikijs/transformers:meta-highlight\"}]}],null],\"remarkRehype\":{\"footnoteLabelProperties\":{\"className\":[\"\"]},\"footnoteBackContent\":\"⤴\"},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{\"WEBMENTION_API_KEY\":{\"context\":\"server\",\"access\":\"secret\",\"optional\":true,\"type\":\"string\"},\"WEBMENTION_URL\":{\"context\":\"client\",\"access\":\"public\",\"optional\":true,\"type\":\"string\"},\"WEBMENTION_PINGBACK\":{\"context\":\"client\",\"access\":\"public\",\"optional\":true,\"type\":\"string\"}},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false},\"legacy\":{\"collections\":false}}","hardware",["Map",11,12,79,80],"ommie",{"id":11,"data":13,"body":75,"filePath":76,"digest":77,"deferredRender":78},{"name":14,"description":15,"shortDescription":16,"category":17,"status":18,"specifications":19,"features":33,"applications":40,"researchAreas":46,"pricing":51,"links":57,"maintainers":63,"institutions":66,"tags":69,"featured":73,"publishDate":74},"Ommie","A versatile and affordable robotics platform designed for education and research. Ommie combines ease of use with advanced capabilities, making it ideal for teaching robotics concepts and conducting HRI experiments.","Versatile educational robot platform for teaching and research","educational","available",{"height":20,"weight":21,"battery":22,"sensors":23,"actuators":28,"computePlatform":32},"0.8 meters","15 kg","6 hours continuous operation",[24,25,26,27],"RGB camera","LIDAR","Ultrasonic sensors","Microphone array",[29,30,31],"Differential drive","1 DOF arm","Pan-tilt head","Raspberry Pi 4 with optional Jetson Nano",[34,35,36,37,38,39],"Easy programming interface","ROS 2 compatible","Modular sensor configuration","Visual programming support","Remote control capability","Educational curriculum included",[41,42,43,44,45],"Robotics education","HRI research","STEM outreach","Programming courses","Navigation studies",[47,48,49,50],"Educational Robotics","Human-Robot Interaction","Navigation","Computer Vision",{"purchase":52,"rental":53},5000,{"daily":54,"weekly":55,"monthly":56},75,400,1200,{"documentation":58,"github":59,"website":60,"purchase":61,"rental":62},"https://docs.ommie.org","https://github.com/semio-community/ommie","https://ommie.org","https://store.semio-community.org/products/ommie","https://store.semio-community.org/rentals/ommie",[64,65],"Semio Community","Oregon State University",[65,67,68],"Tufts University","Yale University",[17,70,71,72],"ros2","mobile-robot","stem",false,["Date","2024-01-20T00:00:00.000Z"],"## Overview\n\nOmmie is an educational robotics platform that bridges the gap between simple educational robots and advanced research platforms. Designed with both educators and researchers in mind, Ommie provides an accessible entry point into robotics while maintaining the capabilities needed for serious research.\n\n## Key Features\n\n### Educational Focus\n\nOmmie comes with a comprehensive educational package including:\n- Structured curriculum for undergraduate courses\n- Tutorial series covering basic to advanced topics\n- Visual programming interface for beginners\n- Python and C++ APIs for advanced users\n\n### Modular Design\n\nThe platform's modular architecture allows for:\n- Easy sensor upgrades and replacements\n- Customizable configurations for different use cases\n- Quick maintenance and repairs\n- Cost-effective operation\n\n## Technical Capabilities\n\n### Navigation\n\nOmmie features advanced navigation capabilities:\n- SLAM (Simultaneous Localization and Mapping)\n- Path planning algorithms\n- Obstacle avoidance\n- Multi-robot coordination support\n\n### Perception\n\nThe integrated sensor suite enables:\n- Object detection and recognition\n- Person tracking\n- Gesture recognition\n- Speech interaction\n\n## Software Support\n\n### Programming Options\n\n```python\n# Example: Simple Ommie control\nfrom ommie import Robot\n\nrobot = Robot()\nrobot.connect()\n\n# Move forward for 2 meters\nrobot.move_forward(2.0)\n\n# Turn 90 degrees\nrobot.rotate(90)\n\n# Say hello\nrobot.speak(\"Hello, I'm Ommie!\")\n```\n\n### ROS 2 Integration\n\nFull ROS 2 support with pre-configured packages:\n- `ommie_navigation`: Autonomous navigation\n- `ommie_perception`: Sensor processing\n- `ommie_control`: Low-level control\n- `ommie_education`: Educational tools\n\n## Educational Resources\n\n### Curriculum Modules\n\n1. **Introduction to Robotics** (4 weeks)\n   - Robot components and systems\n   - Basic programming concepts\n   - Sensor fundamentals\n\n2. **Mobile Robotics** (6 weeks)\n   - Kinematics and dynamics\n   - Localization techniques\n   - Path planning algorithms\n\n3. **Human-Robot Interaction** (4 weeks)\n   - Social robotics concepts\n   - Interaction design\n   - User studies\n\n### Learning Materials\n\n- 50+ hands-on exercises\n- Video tutorials library\n- Online simulation environment\n- Assessment tools for educators\n\n## Research Applications\n\nDespite its educational focus, Ommie has been used in numerous research projects:\n- Navigation in crowded environments\n- Multi-robot coordination\n- Educational robotics studies\n- Accessibility research\n\n## Community\n\n### User Base\n\n- 200+ universities worldwide\n- 5,000+ students trained annually\n- Active educator community\n- Regular webinars and workshops\n\n### Support\n\n- Comprehensive documentation\n- Active forum community\n- Educational Discord server\n- Monthly educator meetups\n\n## Getting Started\n\n### Quick Setup\n\n1. Unbox and charge the robot\n2. Download the Ommie app\n3. Connect via WiFi\n4. Run the setup wizard\n5. Start with tutorial projects\n\n### Training Options\n\n- Online self-paced courses\n- Instructor training workshops\n- Summer bootcamps for educators\n- Custom training programs\n\n## Specifications Summary\n\n| Feature | Specification |\n|---------|--------------|\n| Dimensions | 80cm × 40cm × 40cm |\n| Weight | 15 kg |\n| Max Speed | 1 m/s |\n| Battery | 6 hours typical |\n| Computing | RPi 4 / Jetson Nano |\n| Connectivity | WiFi, Bluetooth, USB |\n| OS | Ubuntu 20.04 |\n\n## Future Development\n\nOngoing improvements include:\n- Enhanced computer vision capabilities\n- Improved battery life\n- Additional sensor options\n- Expanded curriculum materials\n- Cloud-based fleet management","src/content/hardware/ommie.mdx","0a60beb78dfa13cc",true,"quori",{"id":79,"data":81,"body":107,"filePath":108,"digest":109,"deferredRender":78},{"name":82,"description":83,"shortDescription":84,"category":85,"status":18,"features":86,"applications":90,"researchAreas":93,"links":95,"maintainers":98,"institutions":99,"tags":102,"featured":78,"publishDate":106},"Quori","A socially interactive robot platform designed for human-robot interaction research","Social robot platform for HRI research","social",[87,88,89],"Social interaction capabilities","Research-grade platform","Community supported",[91,92],"Human-robot interaction research","Social robotics studies",[48,94],"Social Robotics",{"documentation":96,"github":97},"https://docs.quori.org","https://github.com/semio-community/quori",[64],[100,101],"University of Pennsylvania","University of Southern California",[103,104,105],"social-robotics","hri","research",["Date","2024-01-15T00:00:00.000Z"],"## Overview\n\nQuori is a socially interactive robot designed for human-robot interaction research. It provides researchers with a capable and standardized platform for conducting HRI studies.\n\n## Features\n\n- Expressive upper body for social interaction\n- Mobile base for navigation\n- Comprehensive sensor suite\n- Open-source software stack\n- Community support and documentation\n\n## Getting Started\n\nFor documentation and resources, visit the [Quori documentation site](https://docs.quori.org).","src/content/hardware/quori.mdx","da27007ffb59dcfd","software",["Map",112,113],"arora",{"id":112,"data":114,"body":147,"filePath":148,"digest":149,"deferredRender":78},{"name":115,"description":116,"shortDescription":117,"category":118,"status":119,"license":120,"language":121,"platform":124,"features":127,"useCases":131,"links":135,"maintainers":139,"institutions":140,"tags":141,"featured":78,"lastUpdate":145,"publishDate":146},"Arora","A robotics orchestration platform for managing multi-robot systems","Orchestration platform for multi-robot systems","framework","stable","MIT",[122,123],"Python","TypeScript",[125,126],"Linux","Docker",[128,129,130],"Multi-robot fleet management","Behavior orchestration","Data collection pipeline",[132,133,134],"Multi-robot research studies","Fleet coordination","Data collection automation",{"documentation":136,"github":137,"website":138},"https://arora.readthedocs.io","https://github.com/semio-community/arora","https://arora.semio.ai",[64],[64],[142,143,144],"orchestration","fleet-management","multi-robot",["Date","2024-11-20T00:00:00.000Z"],["Date","2023-06-15T00:00:00.000Z"],"## Overview\n\nArora is a robotics orchestration platform designed to simplify the management of multi-robot systems in research environments.\n\n## Features\n\n- Multi-robot fleet management\n- Behavior orchestration engine\n- Real-time monitoring\n- Data collection automation\n\n## Getting Started\n\nDocumentation and installation instructions are available at [https://arora.readthedocs.io](https://arora.readthedocs.io).","src/content/software/arora.mdx","1de3d410b87da673","events",["Map",152,153],"hri-2025",{"id":152,"data":154,"body":220,"filePath":221,"digest":222,"deferredRender":78},{"name":155,"description":156,"type":157,"format":158,"startDate":159,"endDate":160,"registrationDeadline":161,"location":162,"organizers":169,"speakers":179,"tracks":192,"topics":199,"links":208,"pricing":212,"capacity":217,"featured":78,"tags":218},"HRI 2025: ACM/IEEE International Conference on Human-Robot Interaction","The 20th Annual ACM/IEEE International Conference on Human-Robot Interaction is the premier venue for presenting and discussing cutting-edge research in human-robot interaction. HRI 2025 brings together researchers, practitioners, and industry leaders to share the latest advances in HRI theory, methods, technologies, and applications.","conference","hybrid",["Date","2025-03-04T00:00:00.000Z"],["Date","2025-03-06T00:00:00.000Z"],["Date","2025-02-15T00:00:00.000Z"],{"venue":163,"city":164,"country":165,"online":78,"coordinates":166},"Melbourne Convention and Exhibition Centre","Melbourne","Australia",{"lat":167,"lng":168},-37.8258,144.9559,[170,174,177],{"name":171,"role":172,"affiliation":173},"ACM SIGCHI","Co-organizer","Association for Computing Machinery",{"name":175,"role":172,"affiliation":176},"IEEE RAS","IEEE Robotics and Automation Society",{"name":64,"role":178,"affiliation":64},"Community Partner",[180,184,189],{"name":181,"title":182,"affiliation":120,"topic":183},"Dr. Cynthia Breazeal","Professor and Dean for Digital Learning","Social Robots and Human Flourishing",{"name":185,"title":186,"affiliation":187,"topic":188},"Dr. Hiroshi Ishiguro","Professor","Osaka University","Android Science and Human-Robot Symbiosis",{"name":190,"title":186,"affiliation":120,"topic":191},"Dr. Julie Shah","Human-Robot Collaboration in Complex Environments",[193,194,195,196,197,198],"Technical Sessions","Late Breaking Reports","Demonstrations","Student Design Competition","Workshops and Tutorials","Video Presentations",[200,94,201,202,203,204,47,205,206,207],"Human-Robot Interaction Theory","Robot Design and Aesthetics","Ethics and Trust in HRI","Collaborative Robotics","Healthcare and Assistive Robotics","Field Studies and Applications","Multi-modal Interaction","Robot Learning from Humans",{"website":209,"registration":210,"program":211},"https://humanrobotinteraction.org/2025/","https://humanrobotinteraction.org/2025/registration","https://humanrobotinteraction.org/2025/program",{"student":213,"academic":214,"industry":215,"virtual":216},350,650,850,150,800,[104,157,103,219,105],"human-robot-interaction","## About HRI 2025\n\nThe ACM/IEEE International Conference on Human-Robot Interaction is the premier venue for showcasing the very best interdisciplinary and multidisciplinary research in human-robot interaction. Researchers from diverse backgrounds including robotics, computer science, engineering, design, behavioral and social sciences come together to define and advance the state-of-the-art in HRI.\n\n## Conference Theme: \"Robots in the Wild\"\n\nHRI 2025's theme focuses on deploying robots in real-world, uncontrolled environments. As robots move from laboratories into homes, workplaces, and public spaces, understanding how they interact with diverse populations in complex, dynamic settings becomes crucial.\n\n## Key Dates\n\n- **Paper Submission Deadline**: October 1, 2024\n- **Notification of Acceptance**: December 15, 2024\n- **Camera-Ready Deadline**: January 15, 2025\n- **Early Registration Deadline**: February 15, 2025\n- **Conference Dates**: March 4-6, 2025\n\n## Program Highlights\n\n### Technical Sessions\n- 80+ full papers presenting cutting-edge research\n- 150+ late-breaking reports on emerging work\n- Interactive poster sessions\n\n### Special Programs\n- **Student Design Competition**: Teams compete to create innovative HRI solutions\n- **Robot Demonstrations**: Live demos of the latest robotic systems\n- **Industry Showcase**: Leading companies present commercial HRI applications\n- **Video Session**: Creative presentations of HRI research and applications\n\n### Workshops & Tutorials\n- \"LLMs for Human-Robot Interaction\"\n- \"Ethics and Responsible Innovation in HRI\"\n- \"Participatory Design Methods for Social Robots\"\n- \"Measuring Trust in Human-Robot Teams\"\n- \"Cross-Cultural Perspectives in HRI\"\n\n## Keynote Speakers\n\n### Dr. Cynthia Breazeal\n**\"Social Robots and Human Flourishing\"**\nExploring how social robots can support human wellbeing, learning, and social connection across the lifespan.\n\n### Dr. Hiroshi Ishiguro\n**\"Android Science and Human-Robot Symbiosis\"**\nExamining the future of human-like robots and their role in understanding human nature and society.\n\n### Dr. Julie Shah\n**\"Human-Robot Collaboration in Complex Environments\"**\nAddressing challenges in developing robots that can effectively partner with humans in dynamic, high-stakes settings.\n\n## Semio Community Involvement\n\nSemio Community is proud to be a Community Partner for HRI 2025. We're organizing several activities:\n\n### Hardware Showcase\nDemonstration of community-driven robotics platforms:\n- Quori social robot demonstrations\n- Hands-on sessions with Ommie platform\n- BeholderBot perception system demos\n\n### Community Workshop\n\"Building Reproducible HRI Research with Open Hardware and Software\"\n- Best practices for reproducible research\n- Introduction to Semio hardware platforms\n- ROS 2 HRI Toolkit tutorial\n- Community collaboration opportunities\n\n### Meetup\nJoin the Semio Community meetup on March 5th, 6:00 PM for:\n- Networking with community members\n- Updates on new initiatives\n- Collaboration opportunities\n- Light refreshments\n\n## Venue Information\n\n### Melbourne Convention and Exhibition Centre\n- World-class facilities in the heart of Melbourne\n- Easy access to public transportation\n- Walking distance to restaurants and hotels\n- Full accessibility for all attendees\n\n### Virtual Participation\n- Live streaming of keynotes and selected sessions\n- Virtual poster sessions with interactive Q&A\n- Access to recorded content for 6 months post-conference\n- Virtual networking opportunities\n\n## Registration\n\n### In-Person Registration Includes:\n- All conference sessions and keynotes\n- Conference proceedings\n- Welcome reception\n- Coffee breaks and lunch\n- Conference dinner (March 5th)\n- Conference bag and materials\n\n### Virtual Registration Includes:\n- Live stream access to main sessions\n- Interactive virtual poster sessions\n- Access to conference proceedings\n- 6-month access to recorded content\n- Virtual networking platform access\n\n## Travel and Accommodation\n\n### Recommended Hotels\n- **Crown Metropol Melbourne** (5-min walk)\n- **Novotel Melbourne South Wharf** (3-min walk)\n- **Holiday Inn Express Melbourne** (10-min walk)\n\nSpecial conference rates available through the registration page.\n\n### Travel Grants\nLimited travel grants available for:\n- Student presenters\n- Researchers from developing countries\n- Early career researchers\n\nApplication deadline: January 15, 2025\n\n## COVID-19 Safety\n\nHRI 2025 follows local health guidelines and implements safety measures including:\n- Optional mask-wearing\n- Hand sanitizing stations\n- Hybrid attendance options\n- Flexible cancellation policy\n\n## Contact\n\nFor general inquiries: info@hri2025.org\nFor Semio Community activities: events@community.semio.ai\n\n## Sponsors\n\n### Platinum Sponsors\n- Major robotics companies and research institutions\n\n### Gold Sponsors\n- Technology companies and foundations\n\n### Community Partners\n- **Semio Community**: Supporting reproducible HRI research\n- Other HRI-focused organizations\n\nJoin us in Melbourne for this landmark conference celebrating 20 years of HRI research and looking toward the future of human-robot interaction!","src/content/events/hri-2025.mdx","e7505cc72f81cfdb","partners",["Map",225,226],"george-mason-university",{"id":225,"data":227,"body":244,"filePath":245,"digest":246,"deferredRender":78},{"name":228,"description":229,"type":230,"category":105,"website":231,"collaboration":232,"location":240,"featured":78,"order":243},"George Mason University","George Mason University is a leading research institution partnering with Semio Community on robotics and human-robot interaction initiatives.","academic","https://www.gmu.edu",{"areas":233,"projects":237,"startDate":239,"active":78},[234,235,236],"Human-Robot Interaction Research","Hardware Development","Educational Programs",[238],"MuSoHu (GMU Helmet)",["Date","2023-01-01T00:00:00.000Z"],{"city":241,"country":242},"Fairfax","United States",1,"## Partnership Overview\n\nGeorge Mason University is an academic partner of the Semio Community, contributing to the development of the MuSoHu (Multi-modal Social Human) helmet platform and advancing research in human-robot interaction.\n\n## Key Contributions\n\n### MuSoHu (GMU Helmet)\n\nGMU is the lead institution developing the MuSoHu helmet system, an innovative wearable device for HRI research.\n\n## Contact\n\nFor partnership inquiries, please contact us through the main Semio Community channels.","src/content/partners/george-mason-university.mdx","299abbb0834b429b"]